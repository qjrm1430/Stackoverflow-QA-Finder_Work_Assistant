import streamlit as st
from typing import Tuple, List, Dict
from utils.vector_store import VectorStore
from utils.llm_chain import LLMChain
from langchain_openai import OpenAIEmbeddings
import os
from dotenv import load_dotenv
from utils.data_loader import load_stackoverflow_data

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


@st.cache_resource
def initialize_vector_store() -> VectorStore:
    """
    ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (ìºì‹±)
    """
    embeddings = OpenAIEmbeddings()
    vector_store = VectorStore(embeddings)

    # ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ë¡œë“œ
    if os.path.exists("faiss_index"):
        vector_store.load_vectorstore("faiss_index")
    else:
        # ë°ì´í„° ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        df = load_stackoverflow_data("data/stackoverflow_qa.csv")
        vector_store.create_vectorstore(df)
        vector_store.save_vectorstore("faiss_index")

    return vector_store


def process_question(
    question: str, vector_store: VectorStore, llm_chain: LLMChain
) -> Tuple[List[Dict], str]:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
    """
    try:
        similar_results = vector_store.get_similar_questions(question)
        llm_response = llm_chain.generate_response(question, similar_results)
        return similar_results, llm_response
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return [], "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def display_results(user_question: str, similar_results: List[Dict], llm_answer: str):
    """
    ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    """
    st.write("### ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸")
    st.write(user_question)

    st.write("### ğŸ” ìœ ì‚¬í•œ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš° Q&A")
    for idx, result in enumerate(similar_results, 1):
        with st.expander(f"ì°¸ê³  ìë£Œ {idx}: {result['question']}", expanded=True):
            st.write(f"**ë‹µë³€:** {result['answer']}")
            st.write(f"**ì›ë³¸ ë§í¬:** [ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ì—ì„œ ë³´ê¸°]({result['link']})")

    st.write("### ğŸ’¡ AI ë‹µë³€")
    st.write(llm_answer)


def main():
    st.set_page_config(page_title="C# Q&A ì±—ë´‡", page_icon="ğŸ’»", layout="wide")
    st.title("C# Q&A ì±—ë´‡ ğŸ¤–")

    # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    vector_store = initialize_vector_store()
    llm_chain = LLMChain()

    # ì‚¬ì´ë“œë°”ì— ì„¤ëª… ì¶”ê°€
    with st.sidebar:
        st.markdown(
            """
        ### ì‚¬ìš© ë°©ë²•
        1. C# ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”
        2. ê´€ë ¨ëœ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš° ë‹µë³€ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤
        3. AIê°€ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤
        """
        )

    # ì‚¬ìš©ì ì…ë ¥
    user_question = st.text_input(
        "C# ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: C#ì—ì„œ stringê³¼ Stringì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    )

    if user_question:
        with st.spinner("ë‹µë³€ì„ ì°¾ëŠ” ì¤‘..."):
            similar_results, llm_response = process_question(
                user_question, vector_store, llm_chain
            )
            display_results(user_question, similar_results, llm_response)


if __name__ == "__main__":
    main()
